{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "0.4.0a0+200fb22\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "% autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "#from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from geant_dataloader import rtnpy_load_data\n",
    "from logistics import *\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# plotting params\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently working on 32 x32 implementation\n",
    "\n",
    "\n",
    "torch.manual_seed(423312)\n",
    "imageSize = 32\n",
    "batchSize = 32\n",
    "manualSeed = 25\n",
    "ngpu = 1\n",
    "mydir=None # will be updated before the run\n",
    "norm_scale = 'unif'\n",
    "epoch=0 #will be updated during the run\n",
    "num_epochs = 30\n",
    "nc =1\n",
    "ndf = 64\n",
    "ngf = 64\n",
    "nz = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Seed: ', 25)\n",
      "Using Cuda\n",
      "cuda:1\n",
      "('Using:', 'gpu', 0L)\n"
     ]
    }
   ],
   "source": [
    "if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "dev_type = '-1to1'\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using Cuda\")\n",
    "    dev_type = 'gpu'\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"Using:\", dev_type, torch.cuda.current_device())\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_array = rtnpy_load_data(\"/home/chris/G4Builds/Geant4HadronCalorimeter/numpy_data/rebinnedGeant4Data_20000Events_64OldSize_32NewSize.npy\", num_events = 100, image_size = imageSize)\n",
    "#image_array1 = rtnpy_load_data(\"/home/chris/G4Builds/Geant4HadronCalorimeter/numpy_data/rebinnedGeant4Data_15000Events_64OldSize_32NewSize.npy\", num_events = None, image_size = imageSize)\n",
    "image_array = rtnpy_load_data(\"numpy_data/geant4Data_30000Events_\"+str(imageSize)+\"ImageSize_800MeV_ScintiAbsoThickness75_8.npz\", num_events = None, image_size = imageSize)\n",
    "#image_array=np.concatenate((image_array1, image_array2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print image_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8b12a6be10>\n"
     ]
    }
   ],
   "source": [
    "#print norm_scale\n",
    "normed_array, scale = normalize(image_array, norm_scale = norm_scale )\n",
    "\n",
    "tensor_array_train = torch.stack([torch.Tensor(i) for i in normed_array[:20000]])\n",
    "tensor_data_train = torch.utils.data.TensorDataset(tensor_array_train)\n",
    "tensor_array_test = torch.stack([torch.Tensor(i) for i in normed_array[20000:]])\n",
    "tensor_data_test = torch.utils.data.TensorDataset(tensor_array_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(tensor_data_train, batch_size=batchSize, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(tensor_data_test, batch_size = batchSize, num_workers = 8)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x, norm_scale = norm_scale, scale = scale, imageSize=imageSize):\n",
    "    x = x.cpu().data.numpy()\n",
    "    #x = 0.5 * (x + 1)\n",
    "   # print x\n",
    "   # x = np.clip(x, 0, 1)\n",
    "    \n",
    "    # this just drops the channel axis\n",
    "    x = x.reshape([-1, imageSize, imageSize])\n",
    "\n",
    "    x = unnormalize(x, scale = scale, norm_scale = norm_scale)\n",
    "    #print x.max()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def plot_reconstructions(model, save_dir=None, epoch = epoch, n_events = num_epochs, latent_dim = nz, conv=True, simple=False, n=4, norm_scale = norm_scale, batchSize = batchSize, scale = scale):\n",
    "    \"\"\"\n",
    "    Plot 10 reconstructions from the test set. The top row is the original\n",
    "    digits, the bottom is the decoder reconstruction.\n",
    "    \"\"\"\n",
    "    # encode then decode\n",
    "    data= next(iter(test_loader))\n",
    "    #print(data[0].shape)\n",
    "    #print norm_scale\n",
    "    if not conv:\n",
    "        data = data.view([-1, 4096])\n",
    "    #data = Variable(data, volatile=True)\n",
    "    true_imgs = data[0]\n",
    "    encoded_imgs = model.encoder(data[0].to(device))\n",
    "    print encoded_imgs.shape\n",
    "    if simple:\n",
    "        encoded_imgs = F.relu(encoded_imgs)\n",
    "    #print(encoded_imgs)    \n",
    "    decoded_imgs = model.decoder(encoded_imgs)\n",
    "    #print(decoded_imgs)\n",
    "    true_imgs = to_img(true_imgs, norm_scale = norm_scale,  scale = scale)\n",
    "    decoded_imgs = to_img(decoded_imgs, norm_scale = norm_scale, scale = scale)\n",
    "    print(decoded_imgs.shape)\n",
    "    \n",
    "    rowsize = n * 2.5\n",
    "    columnsize = 4\n",
    "    fig, axn = plt.subplots(figsize=(rowsize, columnsize))\n",
    "    cmap = sns.cubehelix_palette(dark = 0.4, light=0.98, gamma = 2.5, hue = 1, start =0, as_cmap=True)\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "\n",
    "        if i == 0:\n",
    "            im = plt.imshow(true_imgs[i], cmap=cmap)\n",
    "        else: \n",
    "            plt.imshow(true_imgs[i], cmap=cmap)\n",
    "        #if i == 0:\n",
    "        #    ax.set_ylabel(\"Real\")\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.yaxis.set_ticks_position('none') \n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Real\", rotation  = 0, fontsize = 13)\n",
    "            ax.yaxis.set_label_coords(-.25,0.5)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i], cmap=cmap)\n",
    "        print(decoded_imgs[i].min(), decoded_imgs[i][0].max())\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Decoded\", rotation  = 0, fontsize = 13)\n",
    "            ax.yaxis.set_label_coords(-.3,0.5)\n",
    "\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.yaxis.set_ticks_position('none') \n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.97, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label(r'Pixel $E_{dep}$ (MeV)', y=0.85)\n",
    "    fig.subplots_adjust(wspace=-0.185, hspace=0.09)\n",
    "    fig.suptitle(r\"DCVAE Real and Decoded Samples of $e^{-}$ $E_{dep}$, \"+ str(latent_dim) + \" Latent Dim \", x=0.52, y = 1.02)\n",
    "          \n",
    "    if save_dir != None:\n",
    "        #learning_rate = '%.0E' % Decimal(lr)\n",
    "      \n",
    "        filename = \"DCVAE_EdepFor\" + str(n_events) + \"Events_\" + str(latent_dim) +\"latentDim_\"+ str(imageSize) + \"x\" +str(imageSize) \\\n",
    "                            + \"Image_Epoch\" + str(epoch) + \"_\" + norm_scale + \"Normalized_\" + str(batchSize) + \"batchSize\"\n",
    " \n",
    "        plt.savefig(save_dir + filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)    \n",
    "    \n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, image_channels=1, h_dim=2304, z_dim=32):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(image_channels, 32, kernel_size=6, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, 64, kernel_size=4, stride=2, padding = 0),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 128, kernel_size=4, stride=2, padding = 0),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(128, 256, kernel_size=4, stride=2, padding = 1),\n",
    "#             nn.ReLU(), # 256 x 2 x 2 = 1024\n",
    "#             Flatten()\n",
    "#         )\n",
    "        \n",
    "#         self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "#         self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "#         self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             UnFlatten(),\n",
    "#             nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "        \n",
    "#     def reparameterize(self, mu, logvar):\n",
    "#         std = logvar.mul(0.5).exp_()\n",
    "#         # return torch.normal(mu, std)\n",
    "#         esp = torch.randn(*mu.size()).to(device)\n",
    "#         z = mu + std * esp\n",
    "#         return z\n",
    "    \n",
    "#     def bottleneck(self, h):\n",
    "#         mu, logvar = self.fc1(h), self.fc2(h)\n",
    "#         z = self.reparameterize(mu, logvar)\n",
    "#         return z, mu, logvar\n",
    "\n",
    "#     def encode(self, x):\n",
    "#         h = self.encoder(x)\n",
    "#         z, mu, logvar = self.bottleneck(h)\n",
    "#         return z, mu, logvar\n",
    "\n",
    "#     def decode(self, z):\n",
    "#         z = self.fc3(z)\n",
    "#         z = self.decoder(z)\n",
    "#         return z\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         z, mu, logvar = self.encode(x)\n",
    "#         z = self.decode(z)\n",
    "#         return z, mu, logvar\n",
    "\n",
    "    \n",
    "    \n",
    "class VAE32(nn.Module):\n",
    "    def __init__(self, image_channels=1, h_dim=1024, z_dim=32):\n",
    "        super(VAE32, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1),  # 16 x 16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1) , # 8 x 8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),  # 4 x 4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, nz, 4,2,1),\n",
    "            #nn.BatchNorm2d(256),\n",
    "           # nn.Conv2d(256, 10, 1),\n",
    "            # setup the non-linearity\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 256 x 2 x 2 = 1024\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=6, stride=2, padding = 0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding  = 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding = 0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=3, stride=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size()).to(device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z =self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 1\n",
    "\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, nz):\n",
    "#         super(VAE, self).__init__()\n",
    "\n",
    "#         self.have_cuda = False\n",
    "#         self.nz = nz\n",
    "\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             # input is (nc) x 28 x 28\n",
    "#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf) x 14 x 14\n",
    "#             nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 2),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*2) x 7 x 7\n",
    "#             nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 4),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # state size. (ndf*4) x 4 x 4\n",
    "#             nn.Conv2d(ndf * 4, 1024, 4, 1, 0, bias=False),\n",
    "#             # nn.BatchNorm2d(1024),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             # input is Z, going into a convolution\n",
    "#             nn.ConvTranspose2d(     1024, ngf * 8, 4, 1, 0, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 8),\n",
    "#             nn.ReLU(True),\n",
    "#             # state size. (ngf*8) x 4 x 4\n",
    "#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 4),\n",
    "#             nn.ReLU(True),\n",
    "#             # state size. (ngf*4) x 8 x 8\n",
    "#             nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 2),\n",
    "#             nn.ReLU(True),\n",
    "#             # state size. (ngf*2) x 16 x 16\n",
    "#             nn.ConvTranspose2d(ngf * 2,     nc, 4, 2, 1, bias=False),\n",
    "#             # nn.BatchNorm2d(ngf),\n",
    "#             # nn.ReLU(True),\n",
    "#             # state size. (ngf) x 32 x 32\n",
    "#             # nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "#             # nn.Tanh()\n",
    "#             nn.Sigmoid()\n",
    "#             # state size. (nc) x 64 x 64\n",
    "#         )\n",
    "\n",
    "#         self.fc1 = nn.Linear(1024, 512)\n",
    "#         self.fc21 = nn.Linear(512, nz)\n",
    "#         self.fc22 = nn.Linear(512, nz)\n",
    "\n",
    "#         self.fc3 = nn.Linear(nz, 512)\n",
    "#         self.fc4 = nn.Linear(512, 1024)\n",
    "\n",
    "#         self.lrelu = nn.LeakyReLU()\n",
    "#         self.relu = nn.ReLU()\n",
    "#         # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def encode(self, x):\n",
    "#         conv = self.encoder(x);\n",
    "#         # print(\"encode conv\", conv.size())\n",
    "#         h1 = self.fc1(conv.view(-1, 1024))\n",
    "#         # print(\"encode h1\", h1.size())\n",
    "#         return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "#     def decode(self, z):\n",
    "#         h3 = self.relu(self.fc3(z))\n",
    "#         deconv_input = self.fc4(h3)\n",
    "#         # print(\"deconv_input\", deconv_input.size())\n",
    "#         deconv_input = deconv_input.view(-1,1024,1,1)\n",
    "#         # print(\"deconv_input\", deconv_input.size())\n",
    "#         return self.decoder(deconv_input)\n",
    "\n",
    "#     def reparametrize(self, mu, logvar):\n",
    "#         std = logvar.mul(0.5).exp_()\n",
    "#         if self.have_cuda:\n",
    "#             eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "#         else:\n",
    "#             eps = torch.FloatTensor(std.size()).normal_()\n",
    "#         eps = Variable(eps)\n",
    "#         return eps.mul(std).add_(mu)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # print(\"x\", x.size())\n",
    "#         mu, logvar = self.encode(x)\n",
    "#         # print(\"mu, logvar\", mu.size(), logvar.size())\n",
    "#         z = self.reparametrize(mu, logvar)\n",
    "#         # print(\"z\", z.size())\n",
    "#         decoded = self.decode(z)\n",
    "#         # print(\"decoded\", decoded.size())\n",
    "#         return decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ConvolutionalAutoEncoder32(ngpu).to(device)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    #print x.shape\n",
    "   # print recon_x.shape\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    # BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD\n",
    "\n",
    "image_channels = 1\n",
    "#model = VAE(nz=3).to(device)\n",
    "model = VAE32(image_channels).to(device)\n",
    "#model.load_state_dict(torch.load('vae.torch', map_location='cpu'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mydir = os.path.join('/home/chris/Documents/MPhilProjects/ForViewing/plots/Geant4/SingleLayerEGun/ConVAE/', \n",
    "                     datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + \"/\")\n",
    "print(mydir)\n",
    "# try:\n",
    "#     os.makedirs(mydir)\n",
    "# except OSError as e:\n",
    "#     if e.errno != errno.EEXIST:\n",
    "#         raise\n",
    "\n",
    "# with open(mydir + 'NetworkInfo.txt', 'w') as f:\n",
    "#     print >> f, 'model:', model\n",
    "epochs = 50    \n",
    "bs=32\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 5 == 0:\n",
    "        plot_reconstructions(model, save_dir=None, conv=True, simple=False, n=5)\n",
    "    for idx, data in enumerate(train_loader,0):\n",
    "        data = data[0].to(device)\n",
    "        #print data.shape\n",
    "        recon_images, mu, logvar = model(data)\n",
    "        loss, bce, kld = loss_fn(recon_images, data, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx == 0:\n",
    "            to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                    epochs, loss.data[0]/bs, bce.data[0]/bs, kld.data[0]/bs)\n",
    "            print(to_print)\n",
    "\n",
    "\n",
    "#     plot_reconstructions(model, save_dir=mydir, n=4, conv=True, epoch = epoch, simple=False)\n",
    "#     train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024])\n",
      "(32, 32, 32)\n",
      "(4.800885e-06, 1.1429203)\n",
      "(6.116056e-05, 5.7024846)\n",
      "(1.7749855e-05, 1.35134)\n",
      "(2.3952866e-06, 2.268291)\n",
      "(1.5933674e-05, 0.84116966)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x288 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_reconstructions(model, save_dir=None, conv=True, simple=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x):\n",
    "    recon_x, _, _ = vae(x)\n",
    "    return torch.cat([x, recon_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x = dataset[randint(1, 100)][0].unsqueeze(0)\n",
    "compare_x = compare(fixed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fake_image = 0\n",
    "for i in range(len(decoded_imgs)):\n",
    "    combined_fake_image += decoded_imgs[i]\n",
    "combined_fake_image = combined_fake_image / len(true_imgs)\n",
    "\n",
    "combined_real_image = 0\n",
    "for i in range(len(true_imgs)):\n",
    "    combined_real_image += true_imgs[i]\n",
    "combined_real_image = combined_real_image / len(true_imgs) - 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(combined_real_image, cmap ='PuOr')\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 10\n",
    "data = torch.FloatTensor(np.random.uniform(low=0,high=20,size= (batchSize,nz,6,6))).to(device)\n",
    "#data = torch.randn(batchSize,nz,6,6).to(device)\n",
    "#print(data)\n",
    "                 \n",
    "decoded_imgs = unnormalize(model.decoder(data).cpu().data.numpy().reshape([-1,32,32]),scale=scale,norm_scale=norm_scale)\n",
    "#print(decoded_imgs)\n",
    "#true_imgs = to_img(true_imgs, norm_scale = norm_scale,  scale = scale)\n",
    "#decoded_imgs = to_img(decoded_imgs, norm_scale = norm_scale, scale = scale)\n",
    "print(decoded_imgs.shape)\n",
    "\n",
    "n=4\n",
    "rowsize = n * 2.5\n",
    "columnsize = 4\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(rowsize, columnsize))\n",
    "cmap = sns.cubehelix_palette(dark = 0.4, light=0.98, gamma = 2.5, hue = 1, start =0, as_cmap=True)\n",
    "im = ax.imshow(decoded_imgs[0], cmap=cmap, vmin=0)\n",
    "plt.colorbar(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (New Pytorch)",
   "language": "python",
   "name": "pytorch04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
